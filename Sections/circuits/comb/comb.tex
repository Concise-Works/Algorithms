\newpage
\subsection{Combinational Logic}

Truth tables quickly grow as $n$ inputs lead to $2^n$ rows in the truth table. So instead, 
we model functions using boolean algebra (e.g., $F = A \cdot B + \overline{C}$), and then implement them using logic gates.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=.9\textwidth]{Sections/circuits/comb/comb.png}
  \caption{1) Shows the desired circuit function, 2) the corresponding truth table, and 3) the boolean logic. From the 
  truth table, we can pick a row, substituting the inputs $A$, $B$, and $C$ into the boolean expression, we expect to see the output corresponding to $F$.
  For example, row 3, $F=\overline{C}\overline{B}A+\overline{C}BA+CB\overline{A}+CBA$, is, $0 = (\overline{0}\cdot 1 \cdot 0) + (\overline{0} \cdot 1 \cdot 0) + (0 \cdot 1 \cdot 0) + (0 \cdot 1 \cdot 0).$}
  \label{fig:comb-logic}
\end{figure}

\begin{Def}[Logic Gates]

    Below are the common logic gates with the addition of the resistor which limits current:
    \begin{center}
        \includegraphics[width=.8\textwidth]{Sections/circuits/comb/logic_gates.png}
    \end{center}

    \noindent
    The resistor has many symbols; However, we focus purely on logic gates in this text, and how we can make 
    more complex logical systems from these basic building blocks.
\end{Def}

\newpage 

\noindent
For example, lets consider just NOT, AND, and OR gates and their truth tables:

\begin{figure}[ht!]
  \centering
  \includegraphics[width=.9\textwidth]{Sections/circuits/comb/logic_gates_2.png}
  \caption{1) NOT gate 2) AND gate 3) OR gate. Recall that inside these gates is a combination of PUNs and PDNs to achieve the desired logic, which here we have abstracted away.}
  \label{fig:nand-nor}
\end{figure}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/logic_gates_3.png}
  \caption{Modeling $F=\overline{C}\overline{B}A+\overline{C}BA+CB\overline{A}+CBA$ with logic gates. Note, 
  we see that the ANDS and ORS have more than 2 inputs; They operate the same way as their 2-input counterparts, just with more inputs.}
  \label{fig:logic-gates-model}
\end{figure}

\newpage 

\begin{theo}[Increasing Gate Input Size]

    Above in Figure \ref{fig:logic-gates-model}, we see AND and OR gates with more than 2 inputs. There are 
    multiple ways to implement these larger gates, observe below:\\

    \noindent
    \includegraphics[width=1\textwidth]{Sections/circuits/comb/increase_gate.png}\\

    \noindent
    1) is a 3 input gate, and 2) is a 4 input gate; This method of attaching the gates in sequential order is called
    \textbf{chaining}. 3) takes a different approach and instead uses a \textbf{tree method}.\\

    \noindent
    \rule{\textwidth}{0.4pt}\\
    
    \noindent
    In terms of $t_{PD}$, assuming all gates have the same delay, \underline{\textbf{chaining grows linearly}} with the number of inputs, and
    the \underline{\textbf{tree method grows logarithmically}} with the number of inputs.

    \textbf{However}, if the gates were to have \textbf{different delays}, introduces \textbf{bottlenecks}; In the case of the tree method, getting 
    an input like $D$ introduces a longer path, while in the sequential method, $D$ has less impact on the overall delay.
    \end{theo}

\begin{theo}[NAND AND NOR - Gate Increase Problem \& Efficiency]

    \underline{NAND and NOR are \textbf{not associative} like AND and OR.} This means that we cannot use the chaining or tree method
    to increase the number of inputs for NAND and NOR gates.\\

    \noindent
    Additionally, NAND and NOR gates are more efficient in CMOS logic, as CMOS is naturally inverting with PUNs and PDNs. Thus, their implementations
    are simpler than AND and OR gates.
\end{theo}

\noindent
To further illustrate that NAND and NOR are functionally complete, observe the below diagram:

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1.1\textwidth]{Sections/circuits/comb/nand_nor_fp.png}
  \caption{ This diagram shows that NOT, AND, and OR gates can be constructed purely from NAND (left) or NOR (right) gates.}
  \label{fig:nand-nor-complete}
\end{figure}

\begin{theo}[Increasing NAND Gate Input Size with 2-input NANDs]

    \label{theo:nand-increase}

    Start with the desired function, e.g., $\overline{A \cdot B \cdot C}$, for clarity $\texttt{NAND}(A,B,C)$.
    We attempt to group inputs into pairs of 2: $\texttt{NAND}(A,B,C) = \texttt{NOT}(\texttt{AND}(A,B,C))$.
    Now we group:\\
    $\texttt{NOT}(\texttt{AND}(A,B,C)) = \texttt{NOT}(\texttt{AND}(\texttt{AND}(A,B),C))$, each AND has 2 inputs:\\

    \noindent
    \includegraphics[width=1\textwidth]{Sections/circuits/comb/increase_gate2.png}\\
    \noindent
    To only use NAND gates, we bring the NOT and AND back together:
    $\texttt{NAND}(\texttt{AND}(A,B),C)$. To replace $A$ and $B$'s AND gate, we substitute with NANDs using Figure (\ref{fig:nand-nor-complete}):\\
    
    \noindent
    \includegraphics[width=1\textwidth]{Sections/circuits/comb/increase_gate3.png}

\end{theo}


\begin{Note}
\textbf{Note:} As we've mentioned before,
chaining vs. tree methods vary differently on $t_{PD}$. Additionally notice that the size of our circuit can differ based
on how we decide to break down our boolean expression. In the above Theorem (\ref{theo:nand-increase}), if we assume
AND gates are slower than NAND gates in this system, the simplified NAND version is faster, and smaller, assuming AND gates are composed of multiple NANDs.
\end{Note}

\newpage 

\subsection{Karnaugh Maps}

To help us find simpler boolean expressions, we can change how we represent our truth table data:

\begin{Def}[Karnaugh Maps]

  \label{def:karnaugh-map}

    A Karnaugh map (K-map) represents truth table data with a format called 
    \textbf{Gray Code}. In Gray Code, columns and rows differ by only one bit of information:\\

    \noindent
    \includegraphics[width=\textwidth]{Sections/circuits/comb/kmap.png}

    \noindent
    1) Shows the truth table for inputs $A$, $B$, and $C$ with output $F$. 2) The corresponding K-map
    (left-most column, $C$, top row, $AB$ respectively). \textbf{Note:} in 2) columns and rows are cyclical, meaning the leftmost and rightmost columns are adjacent, as are the top and bottom rows.
    Hence with 3), we can represent our truth table as a 3D cube (Formatted $ABC$). The red arrow in both 2) and 3) indicate adjacency. We extend this to 4 inputs:\\

    \noindent
    \includegraphics[width=\textwidth]{Sections/circuits/comb/kmap2.png}

    \noindent
    For inputs 5 and 6, we need an additional dimension, building a $4 \times 4 \times 4$ k-map. Anything beyond 6 inputs
    becomes difficult to visualize, so algorithms become more integral in the simplification process.
\end{Def}

\newpage 

\noindent 
Now to actually use this k-map to simplify we introduce the following method:
\begin{Def}[Simplifying with Implicants \& Prime Implicants]

    An \textbf{implicant} is a set of adjacent 1s in a k-map, whose width and length are a power of 2 (i.e., 1, 2, 4, 8, $\dots$).
    An implicant that is not a proper subset of another implicant (i.e., not contained within another implicant) is called a \textbf{prime implicant}.

    \noindent
    \rule{\textwidth}{0.4pt}\\

    \noindent
    \textbf{Name of the game:} Find the smallest set of prime implicants that cover all 1s in the k-map. Then translate
    each member of such set into a product term (e.g., top row $AB:=01\to \overline{A}B$). Then sum all 
    found product terms to yield the simplified boolean expression:\\

    \noindent
    \includegraphics[width=\textwidth]{Sections/circuits/comb/imp.png}

    \noindent
    1) The red singleton implicant translates to $\overline{A}\overline{B}C$. The blue pair translates to $A\overline{C}$, yielding the simplified expression
    $F=\overline{A}\overline{B}C + A\overline{C}$. \textbf{Note:} In the second term we dropped $B$, as despite its value switching, it
    did not affect the output.\\
    
    \noindent
    2) Red group: $\overline{A}C$, blue group: $\overline{B}$, yielding $F=\overline{A}C + \overline{B}$, which demonstrates that
    finding \underline{\textbf{larger groups} lead to smaller terms}, and thus, a simpler expression.
\end{Def}

\noindent 

\begin{theo}[Prime Implicants \& Uniqueness]

    Though we look for the smallest set of prime implicants, there may be multiple such sets (i.e., same size, different members) that cover all 1s in the k-map.
\end{theo}

\begin{Tip} Think of our 1 sets as capturing the truth table in its truth states (i.e,. when $A$ is this, and $B$ is this, the 
  output is true!). We combine all such states to reflect the overall behavior (i.e., if this state or this state is true, the output is true!).

  Recall from discrete math, this is called the disjunctive normal form (DNF) of a boolean function. We can do the same with 0s, called the
  conjunctive normal form (CNF) of a boolean function, where we specify which states we don't want; Though we won't explore CNF here.
\end{Tip}

\newpage 

\noindent
Let us explore an example with 4 inputs:

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/imp2.png}
  \caption{1) and 2) A 4-input k-map with 4 prime implicants highlighted. 1) Yields $F=\overline{B}C+D+B\overline{C}+\overline{C}A$. 2) Yields $F=\overline{B}C+D+B\overline{C}+A\overline{B}$.}
  \label{fig:imp-example}
\end{figure}

\begin{theo}[Glitches from Implicant Hopping]

  Moving between two prime implicants (product terms) which do not overlap causes glitches;
  Because each is solely driving the output.
  So switching one off one and the other on, briefly exhibits undefined behavior, due to the $t_{PD}$ (uncertainty period).
\end{theo}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/glitch.png}
  \caption{To the left shows the k-map of a function consisting of two prime implicants (circled red).
  The right shows the logic gate implementation and its resulting sum of products expression. }
  \label{fig:glitch-example}
\end{figure}

\noindent
We deviate from our game of smallest sets, adding redundancy:
\begin{theo}[Resolving Implicant Glitches with Redundancy]

    To resolve glitches caused by gaps between prime implicants, we can add another 
    prime implicant that fills that gap to help hold the output steady during transitions.
\end{theo}

\clearpage

\noindent
To further illustrate the glitch we visualize the voltage over time:\\

\vspace{1em}

\begin{figure}[ht!]
  
  \hspace{-7em} \includegraphics[width=1.3\textwidth]{Sections/circuits/comb/glitch2.png}
  \caption{$A$ and $B$ inputs remain steady high (1), while $C$ transitions from high (1) to low (0).
  Based on Figure \ref{fig:glitch-example}, the output $Y$ should remain high (1); However,
  due to both products relying on $C$, the output is briefly undefined for $t_{PD}$.}
  \label{fig:glitch-voltage}
\end{figure}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/glitch3.png}
  \caption{By adding the redundant prime implicant (in red), we ensure steady output during transitions. In particular,
  the output isn't solely reliant on $C$ during its transition, thus avoiding the glitch.}
  \label{fig:glitch-resolved}
\end{figure}

\clearpage

\noindent
\subsection{Multiplexers \& Read-only Memory}

Below observe the table we've used in our k-map Definition (\ref{def:karnaugh-map}):

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/mux.png}
  \caption{1) A three input truth table for when $S$ is 0 $D_0$ is the output, and when 
  $S$ is 1, $D_1$ is the output. 2) A diagram simplification of the truth table: $S$ has two controls 1 and 0, which chooses between data inputs $D_1$ and $D_0$ respectively.}
  \label{fig:mux}
\end{figure}

\noindent
This new combination device we've created has a name:
\begin{Def}[Multiplexer]

  \label{def:mux}

    A \textbf{multiplexer} (MUX) is a combinational logic device that selects one of many data inputs
    based on control inputs, outputting the selected data input. In Figure (\ref{fig:mux}), 
    $S$ the control input and $D_0$, $D_1$ the data inputs.

    More generally, a MUX with \underline{$n$ control inputs can select from $2^n$} data inputs. Vice-versa
    a MUX with \underline{$m$ data inputs, has $\log_2(m)$} control inputs.\\

    \noindent
    \includegraphics[width=.93\textwidth]{Sections/circuits/comb/mux2.png}

    \noindent
    E.g., a 4-to-1 MUX: 2 control inputs $S_1$ and $S_0$ selecting from 4 data inputs.
\end{Def}
\newpage

\noindent
In the above Definition (\ref{def:mux}), we simply showed a 4-1 MUX; However, they are much more
complicated devices:

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1\textwidth]{Sections/circuits/comb/mux3.png}
  \caption{This shows that under the hood is composed of a tree of 2-to-1 MUXes.}
  \label{fig:mux-complex}
\end{figure}

\begin{theo}[Building Larger MUXes from 2-to-1 MUXes]

    Any larger MUX can be built from a tree of 2-to-1 MUXes. In particular, an $n$-to-1 MUX
    requires $n-1$ of 2-to-1 MUXes to build. \hfill \cite{quora_mux_12_to_1}
\end{theo}
\begin{theo}[MUX as Boolean Function Implementers]

    MUXes are functionally complete, i.e., can implement any boolean function.\\

    \noindent
    \includegraphics[width=1\textwidth]{Sections/circuits/comb/mux4.png}

    \noindent
    E.g., 1) shows a NOT, 2) an AND, and 3) an OR gate implemented with a 2-to-1 MUX.
\end{theo}

\newpage