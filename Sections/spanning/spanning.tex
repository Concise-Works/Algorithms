\newpage 
\section{Spanning trees}

\begin{Def}[Spanning Tree]

    A \textbf{spanning tree} of a graph $G$ is a subgraph containing edges to each $n\in G$ without cycles.
\end{Def}

\begin{Def}[Minimum Spanning Tree (MST)]

    A \textbf{minimum spanning tree} of a graph $G$ is a spanning tree with the smallest sum of edge weights.
\end{Def}

\begin{figure}[h]
    
    \hspace{-7em}
    \includegraphics[width=1.3\textwidth]{./Sections/spanning/mst_example.png}

    \caption{Example of a graph with MST highlighted in red.}
    \label{fig:mst_example}

\end{figure}
\noindent
This tree visits each node once taking the shortest path which connects all of them.

\noindent
\textbf{Possible Algorithms:}
\begin{itemize}
    \item \textbf{Prim's:} Start with some root node s. Grow a tree T from s outward. At each step, add to T the cheapest edge e with exactly one endpoint in T.
    \item \textbf{Kruskal's:} Start with \( T = \emptyset \). Consider edges in ascending order of weights. Insert edge e in T unless doing so would create a cycle.
    \item \textbf{Reverse-Delete:} Start with \( T = E \). Consider edges in descending order of weights. Delete edge e from T unless doing so would disconnect T.
    \item \textbf{Bor≈Øvka's:} Start with \( T = \emptyset \). At each round, add the cheapest edge leaving each connected component of T. Terminates after at most \( \log(n) \) rounds.
\end{itemize}

\noindent
Next we revisit cycles and introduce \textbf{cuts}, which will have important implications when approaching this problem.

\newpage

\begin{Def}[Endpoint]
    
        An \textbf{endpoint} is either end of an edge. So for edge $e = u\leftrightarrow v$, $u$ and $v$ are endpoints. If
        $u\to v$, then $v$ is an endpoint of $u$.
\end{Def}
\begin{Def}[Cut]

    Given a graph $G$, partitioning of the nodes into a set is called a \textbf{cut}, say $G'$. Nodes, with exactly one endpoint in $G'$, are the \textbf{cut-set}.
    
\end{Def}



\begin{figure}[h]
    \centering
    \includegraphics[width=.8\textwidth]{./Sections/spanning/cut_example.png}

    \caption{1) a graph $G$. 2) The same graph with cut $G'$. Here, $G'=\{a\}$ and our cut-set contains edge-pairs $(a,b)$ and $(a,c)$. Where the edge $(d,c)$ is not included as the cut $G'$ does not intersect it.}
    \label{fig:cut_example}
\end{figure}
\begin{theo}[Cycles \& Cut-sets]

    If a cut-set crosses a cycle, then the cut-set intersects an even number of edges in the cycle.\\
    As what comes in, must come out.
\end{theo}
\noindent
Given Figure (\ref{fig:cut_example}), the cut-set $G'$ intersects the cycle $(a,b,c)$, yielding an even cut-set.
\begin{theo}[Cycle Property]
    
    In a graph with a cycle, the edge with the largest weight in that cycle is not in the MST.
    As taking an edge from a cycle does not disconnect the graph, the largest edge is not necessary.
\end{theo}
\begin{theo}[Cut Property]

    Given a graph $G$ and a cut-set $C$, where $e$ is the lightest-edge in $C$; $e$ must be in the MST. As if $e\notin G$ and $G$ is an MST, adding $e$ creates a cycle. By the cycle property, $e$ must replace the heaviest edge in that cycle.
\end{theo}


\newpage
\noindent
\textbf{Example:} Given the below Figure (\ref{fig:cut_property}), point $e$ must be in the MST to connect all nodes (cut property). Say dash-edge $f$ is the largest in its cycle, then $f$ is not in the MST (cycle property).
\begin{figure}[h]
    \centering
    
    \includegraphics[width=1\textwidth]{./Sections/spanning/cut_property.png}
    
    \caption{A graph cut into two disjoint sets, with a highlighted edge $e$ and a dashed edge $f$.}
    \label{fig:cut_property}
\end{figure}

\vspace{-1em}
\begin{theo}[Prim's Algorithm]

    \label{theo:prim}
    Given a connected graph $G$ with $n$ nodes and $m$ edges, we produce the MST via:
    \begin{enumerate}
        \item [(i.)] Initialize an MST table $T$, and a priority queue $Q$ with each $n$ of weight $\infty$.
        \item [(ii.)] Start a round with an arbitrary node $s$, evaluating children nodes $v$.
        \item [(iii.)] Update each $T[v]=s$, if $w(s,v)$ is lighter than $T[v]$.
        \item [(iv.)] End this round, take the top node in $Q$ as the new $s$, repeat (ii.)-(iv.) until all $n\in T$.
    \end{enumerate}
    \noindent

\end{theo}

\vspace{-4em}
\begin{figure}[h]
    \centering
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering

        \vspace{2em}
      
        \includegraphics[height=2in]{./Sections/spanning/prims_order.png}
        
    \end{minipage}%
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering

        \vspace{2em}
        $$ \begin{matrix} 
        \text{NODE} & \text{PARENT}\\
        a: & \text{NULL}\\ 
        b: & a\\ 
        c: & a\\ 
        d: & c\\ 
        e: & c\\ 
        g: & e\\ 
        f: & e\\ 
        h: & g 
        \end{matrix} $$
    \end{minipage}
    \hfill 
    \caption{Prim's Alg. in the order $a\to b \to c \to e \to d \to g \to f \to h$, and a parent table.}
    \label{fig:prim_example}
\end{figure}

\noindent 
The above example shows how our parent table will result with the following table. Next we will discuss in detail how one could approach implementation.

\newpage
\begin{Tip}
    Live Demo of Prim's Algorithm \url{https://youtu.be/0jtSwQIXpKA?si=dFtmJzSQXPg6MKZW}.
\end{Tip}

\vspace{-1em}
\begin{Func}[Prim's Algorithm - \texttt{PALG()}]
    \textbf{Input:} A connected, undirected graph \( G\) of $V$ nodes. With weights \( w(u, v) \), and $u,v\in V$.\\
    \textbf{Output:} Minimum Spanning Tree (MST) formed by edges \( T<(v, \texttt{parent}[v])> \)\\

    \vspace{-.5em}
    \begin{algorithm}[H]
        \label{algo:prim}
        $Q<weight, node>$; \tcp {Min-heap of <key, data>}
        $V.forEach$(($v$) => $\{Q[v]\gets \infty\}$); \tcp{for each $v\in V$ set it's weight to $\infty$}
        $Q[V_0]\gets 0$; \tcp{Picking arbitrary node $V_0$, pushing it to the top of $Q$}
        $T$; \tcp{Hashtable where $T[u]$ is the parent $v$ of $u$}
        
        \vspace{.5em}
        \While{\( Q \neq \emptyset \)}{
            $ u \gets Q.Extract() $\;

            \vspace{.5em}
            \ForEach{\(v \in G[u] \)}{
                    
                \vspace{.5em}
                \If{$(v\in Q)$ and $(w(u,v)<Q[v])$}
                {
                    \tcp{Edit the node's weight in $Q$ then re-balance.}
                    $Q[v]\gets w(u,v)$\;
                    $Q.DecreaseKey(v)$\;
                    $T[v]\gets u$\;
                }

            }
            
            % \For{each \( v \in G[u] \)}{
            %     \If{\( v \notin V \text{ and } w(u, v) < \texttt{key}[v] \)}{
            %         \( \texttt{key}[v] \gets w(u, v) \)\;
            %         \( \texttt{parent}[v] \gets u \)\;
            %         \( Q.\texttt{Decrease-Key}(v, \texttt{key}[v]) \)\;
            %     }
            % }
        }
        \KwRet{$T$}
    \end{algorithm}
    \noindent\rule{\textwidth}{0.4pt}

    \noindent
    \textbf{Correctness:} We run a form of BFS on the graph, which touches every node. BFS creates levels each iteration, resulting in a cut-set with an end-point $G[u]$.
    By the cut property, any new lightest edge $w(u,v)$ is added or replaces a heavier edge in $T$. Thus forming an MST as all nodes are considered.\\
    \textbf{Time Complexity:} $O((n+m)\log n)$. Line 7 at worse checks every adjacency, $O(n+m)$, for $m$ edges of $n$ nodes. 
    Say lines 8-9 takes $O(1)$ time to find $v\in Q$ via hash-table. Line 10 takes $O(\log n)$ time to re-balance the heap.
    Thus, $O((n+m)\log n)$ or $O(m\log n)$.\\
    \textbf{Space Complexity:} $O(n+m)$, as we at most store the data items a hash-table representation of our graph.
\end{Func}

\noindent
\underline{\textbf{Note:} Lines 8 to 10 may require additional implementation.} Since basic min-heaps only store weights, one 
might need a direct reference to each member in the heap. Say a reference hash-table $R$, where $R[v]$ 
points to $v$ node in $Q$. Once we update $R[v]$, we tell the $Q$ to sort the new $v$ weight. We say
``$DecreaseKey$'' as our new weight should be lighter, bubbling up the heap.\\

\noindent
To check if a node has been visited before, doesn't matter in our case, as we update our solution $T$ with 
a better solution once it is found. We additionally discard the lightest node each round to avoid infinite loops. If one wanted to, they could use $T$'s entries as a visited list. If entries are
undefined upon access, then they have not been visited.\\

\newpage 

\begin{figure}[h]
\centering

        

\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        



\includegraphics[height=5in]{./Sections/spanning/prims_alg.png}

        \caption{A diagram illustrating the pattern of Prim's Algorithm through each iteration.}
        \label{fig:prim_example}
    \end{figure}



\noindent
The above diagram shows Prim's algorithm each round, pick the lightest edge at the top of the heap, check its degrees which have not been, 
update weights, re-balance the heap, and repeat. The algorithm will terminate when all nodes have been picked from the heap.\\ 

\newpage
\begin{Proof}[Prim's Hash-tables vs. Min-heaps Implementation]
    Say we had a hash-table of priorities where $R[v]$ returns weight $w(u,v)$:
    % Under light loads, a hash-table preforms better than a min-heap. However, under heavy loads, a min-heap.
    \begin{itemize}
        \item \textbf{Hash-table} - \textbf{Extract:} $O(n)$, search all indices, \textbf{Decrease-Key:} $O(1)$, update $R[v]$.
        \item \textbf{Min-heap} - \textbf{Extract:} $O(1)$, top element, \textbf{Decrease-Key:} $O(\log n)$, re-balance heap.
    \end{itemize}
    \begin{center}
    \includegraphics[height=2.3in]{./Sections/spanning/alg.png}
    \end{center}

    line 5 stores all $n$ nodes to be visited $O(n)$, line 7 iterates all neighbors for each $n$. Let all edges be $m$, then $\sum_{v \in n} \text{degree}(v)=m$.
    Since line 6 is $O(1)$, we have $O(n+m)$ for iterating all edges. Now for every edge, we might evaluate Decrease-Key, which is $O(\log n)$. This gives us 
    $O((n+m)\log n)$, or $O(m\log n)$.
    
    When using a hash-table, line 6 becomes $O(n)$, and Decrease-Key is $O(1)$. Thus,\\
    $O((n(n)+m)\cdot 1)= O(n^2+m)$ or $O(n^2)$. Hence,

    \begin{center}
        \textbf{Hash-table:} $O(n^2)$. \textbf{Min-heap:} $O(m\log n)$.\\
    \end{center}

    \noindent
    For any connected graph $n-1\leq m \leq \frac{n(n-1)}{2}$, where $m$ is the number of edges. Most often $m$ is much less than $n$, making the min-heap the better choice.
    E.g., say $m=\frac{n^2}{2}$, then $O(n^2)$ vs. $O(n^2\log n)$, hash-table wins. However, say $m=\frac{n}{2}$, then $O(n^2)$ vs. $O(n\log n)$, min-heap wins.
\end{Proof}

\begin{theo}[Prim's Hash-tables vs. Min-heaps]

    For Prim's algorithm,\\
    when $m \leq n$, min-heap is better ($O(n\log n)<O(n^2)$). When $m$ is significantly larger than $n$, hash-tables are better ($O(n^2)<O(n^2\log n)$).
\end{theo}
\newpage
\subsection{Union-Find Data Structures}
\begin{Def}[Union-Find Data Structure]

    A \textbf{Union-Find} data structure is a data structure that keeps track of a set of elements partitioned into multiple disjoint subsets. 
    It supports two useful operations: \textbf{Union:} Merge two subsets into a single subset. \textbf{Find:} Determine which subset a particular element is in.
\end{Def}

\noindent
We \textit{could} simply use a hash-table to keep track of the parent of each node, which gives us\\ 
\textbf{Find O(1); However, Union is $\mathbf{O(n)}$}, as we would have to update every node to its new parent. Given a large set of $n$ nodes, with $m$ edges in a hash-table, to find and union all $n$ nodes
results in \textbf{$\mathbf{O(n^2+m)}$}, as for every $n$ we find, we make $n$ updates, where our finds accumulate to the number of total edge connections.\\

\noindent
\textbf{Scenario - \textit{Follow The Leader:}}
Say you have $n$ people playing rock-paper-scissors. If $n_i$ beats $n_j$, then $n_j$ follows $n_i$. This 
creates large sets of people following a leader. When leader $n_k$ beats $n_i$, $n_i$ follows $n_k$ with $n_i$'s followers tagging along.\\

\noindent
Say we are trying to figure out which component $n_x$ is in. We ask $n_x$, ``who is your leader,'' they say $n_i$, then $n_i$ says $n_k$, and $n_k$ replies, ``I am the leader.'' 
Therefore $n_x$ is in group $n_k$.
\begin{Def}[Forest]

    A \textbf{forest} is a collection of disjoint trees, where each tree has a \textbf{representative} $r$ node. We may
    union-join trees $A$ and $B$ by making $A$ be $B$'s representative. Where $b\in B$ still point to $B$ and $B$ points to $A$.

    \underline{Trees $S$ with smaller heights should be added to bigger trees $B$.} As height indicates the number of nodes who report to a leader.
    By adding the bigger tree to the smaller, we increase the time complexity of finding leaf nodes.

\end{Def}

\vspace{-3.5em}
\begin{figure}[h]
    \centering
    \includegraphics[height=2.3in]{./Sections/spanning/forest-diag.png}
    
    \vspace{-2em}
    \caption{Showing disjoint nodes Union-Join with each other.}
    \label{fig:forest_diag}
\end{figure}

\noindent
In the above figure nodes we see in step two we have two disjoint trees, with leaders $a$ and $c$. In step three we join $a$ and $c$ by making $c$ point to $a$. Finally $e$ points to $a$ to join the group.\\

\noindent
We see a lot of redundancy, with nodes $n_x$ reporting to leaders $n_i$, until a final leader $n_k$ is reached. We may improve this overtime by setting $n_x$'s leader to $n_k$ directly.\\

\vspace{-3em}
\begin{figure}[h]
    \centering
    \includegraphics[height=2.3in]{./Sections/spanning/path_compression.png}
    
    \vspace{-1em}
    \caption{Showing a forest compress over multiple finds.}
    \label{fig:path_compression}
\end{figure}
\noindent
Given the figure above, we first ask $g$ who their leader is, they report to $c$ who reports to $a$. We now set $g$'s leader to $a$. We do the same for $f$ and $d$. Now once
we ask $g,f,$ or $d$ who their leader is, they report to $a$ directly without the need to traverse the tree. This is called \textbf{Path Compression}.
\begin{Def}[Path Compression]

    \textbf{Path Compression} is a technique used in Union-Find data structures to flatten the structure of the tree. 
    After finding the leader of a node in a whole component, we set the node's parent directly to that leader. This reduces the time complexity of find operations for subsequent queries.
\end{Def}

We compare all of our techniques in the following table:
\begin{table}[h!]
  \centering
  \resizebox{\textwidth}{!}{%
    \renewcommand{\arraystretch}{1.5}%
    \setlength{\tabcolsep}{5pt}%
    \rowcolors{2}{OliveGreen!5}{}%
    \begin{tabular}{>{\columncolor{OliveGreen!15}}l | c c c}
      \rowcolor{OliveGreen!20}
      Operation\textbackslash{}Implementation 
        & Simple Hash-table 
        & Forest 
        & \makecell[l]{\rule{0pt}{2.5ex}Forest with\\ Path Compression} \\
      \hline
      Find (worst-case)
        & $\Theta(1)$
        & $\Theta(\log n)$
        & $\Theta(\log n)$ \\ \hline
    \cellcolor{OliveGreen!15}Union of sets $A,B$ (worst-case)
        & $\Theta(n)$
        & $\Theta(1)$
        & $\Theta(1)$ \\ \hline
    \makecell[l]{\rule{0pt}{2.6ex} Total for $n$ unions and $n$ finds,\\ starting from singletons}
        & $\Theta(n^2)$
        & $\Theta(n\log n)$
        & $\Theta\bigl(m\cdot\alpha(m,n)\bigr)$ \\
    \end{tabular}%
  }
  \caption{Time-complexity comparison of different implementations. Where $\alpha(m,n)$ is the inverse Ackermann function, which grows very slowly.}
  \label{tab:uf-complexity}
\end{table}


\newpage
\noindent 

\begin{theo}[Kruskal's Algorithm]

    \label{theo:kruskal}
    Given a connected graph $G$ of $V$ nodes and $E$ edges, we produce the MST via:
    \begin{enumerate}
        \item [(i.)] Sort all $e\in E$ by weight in ascending order into an array $W$.
        \item [(ii.)] Initialize a forest $T$ with all $V$ nodes as singletons.
        \item [(iii.)] For each $e\in W$ Union-find its endpoints $u$ and $v$.
        \begin{itemize}
            \item If $u$ and $v$ are in different sets, Union-join $u$ and $v$.
        \end{itemize}
    \end{enumerate}
    \noindent
    Return the resulting forest $T$ as the MST.
\end{theo}

\begin{Func}[Kruskal's Algorithm - \texttt{KALG()}]
    \textbf{Input:} a connected graph $G$ of $V$ nodes and $E$ edges.\\
    \textbf{Output:} Minimum Spanning Tree (MST) formed by forest Union-find data structure.\\

    \vspace{-.5em}
    \begin{algorithm}[H]
        \label{algo:prim}
        $W[\ ]\gets Sort(E)$; \tcp {Sort all edges by weight}
        $T\gets new \ UnionFind(G)$; \tcp{new forest with all $G$'s nodes as singletons}

        \vspace{.5em}
        \For {$i=1$ to $W.size()$}{
            $(u,v)\gets e$; \tcp{Get the endpoints of $e$}

            \vspace{.5em}
            \If{$T.Find(u)\neq T.Find(v)$}{
                $T.Union(u,v)$; \tcp{Union-join $u$ and $v$}
            }
        }
        \KwRet{$T$}
    \end{algorithm}
    \noindent\rule{\textwidth}{0.4pt}

    \noindent
    \textbf{Correctness:} Sorting edges in ascending order, ensures lightest possible edge is picked first before redundancy checks with Union-find, which avoids cycles (Line 5).
    Any new unique edge $e$ is added to the MST. This yields a connected graph as all edges are considered no matter their weight.\\
    \textbf{Time Complexity:} $O(E \log E)$ or $O(E \log V)$. Line 1 sorts all edges, which takes $O(E \log E)$ time, where $E$ is at most $V^2$ (all nodes connect to each other).
    Thus, $\Theta(E \log_2 V)$ is $O(E \log_2 E)$ as the exponent to reach $V$ and $E$ are the same. Then iterating through all $E$ edges; 
    actions are one-to-one for each \textit{find-merge} operation $E_i$. This results in one operation per edge, rather than a compounded combination of operations, like a nested for-loops.\\
    \textbf{Space Complexity:} $O(V+E)$, as we at most store the data items a hash-table representation of our graph.
\end{Func}

\noindent
\textbf{Note:} Lines 1 and 4, might require additional implementation such as a reference hash-table $R$ to keep track of edges and their end-points after sorting.

\newpage

\begin{Exercise} Let there be a graph $G(V,E)$ with an MST $T$ and a shortest paths tree $S$. Now 
    suppose a weight of 1 is added to each edge in $G$.
\begin{enumerate}
    \item Will the MST $T$ change?
    \item Will the shortest paths tree $S$ change?
\end{enumerate}
\end{Exercise} 

\begin{Exercise} Let there be a graph $G(V,E)$ with an MST $T$ and a shortest paths tree $S$.
    Suppose a new edge $e$ is added to $G$.
    \begin{enumerate}
        \item The weight of $e$ is the heaviest in $G$.
            \begin{enumerate}
                \item Will the MST $T$ change?
                \item Will the shortest paths tree $S$ change?
            \end{enumerate}
        \item The weight of $e$ is the lightest in $G$.
            \begin{enumerate}
                \item Will the MST $T$ change?
                \item Will the shortest paths tree $S$ change?
            \end{enumerate}
    \end{enumerate}
\end{Exercise}

\noindent\rule{\textwidth}{0.4pt}

\vspace{1em}
\begin{Answer} 
    \begin{enumerate}
        \item \textbf{No.} All edges in $T$ are still the lightest edges in $G$.
        \item \textbf{Yes.} Shortest paths is not MST. Here is a counter example:\\
        \vspace{1em}
        \includegraphics[height=1in]{./Sections/spanning/counter.png}\\

        \vspace{-2em}
        \noindent
        The shortest path from $s$ to $t$ changed when all edges were increased by 1.
    \end{enumerate}
\end{Answer}

\begin{Answer} 
    \begin{enumerate}
        \item \begin{enumerate}
            \item \textbf{No.} By the cycle property, the heaviest edge is not necessary in the MST.
            \item \textbf{Yes.} The new edge may present a shorter path. Here is a counter example:\\
            \includegraphics[height=1.1in]{./Sections/spanning/counter_2.png}\\
        \end{enumerate}
        \item \begin{enumerate}
            \item \textbf{Yes.} By the cycle property, an existing edge will be replaced by a lighter edge.
            \item \textbf{Yes.} Consider a long expensive path, a new edge may present a shorter path.
        \end{enumerate}
    \end{enumerate}
    
\end{Answer}